#!/usr/bin/env python3
import cv2
import time
import uinput
import mediapipe as mp

# ===== Configura√ß√µes =====
MIN_DET = 0.6
MIN_TRK = 0.6
CALIBRATION_S = 2.0     # tempo inicial para estabilizar c√¢mera
CAM_INDEX = 0           # √≠ndice da webcam

# ===== Filtro Temporal =====
GESTURE_WINDOW_SIZE = 8  # n√∫mero de frames para confirmar gesto
CONSISTENCY_THRESHOLD = 0.75  # 75% das amostras devem ser iguais

# ===== Dispositivo virtual (uinput) =====
kb = uinput.Device([uinput.KEY_RIGHT, uinput.KEY_LEFT, uinput.KEY_HOME, uinput.KEY_END])

# ===== MediaPipe =====
mp_hands = mp.solutions.hands
hands = None  # Ser√° inicializado depois

# ===== Utilidades de dedos =====
TIP = { "thumb": 4, "index": 8, "middle": 12, "ring": 16, "pinky": 20 }
PIP = { "thumb": 3, "index": 6, "middle": 10, "ring": 14, "pinky": 18 }

def finger_extended(lm, tip_idx, pip_idx, handed_label):
    tip = lm[tip_idx]
    pip = lm[pip_idx]
    if tip_idx == TIP["thumb"]:
        # polegar: eixo X depende da m√£o (mais rigoroso)
        if handed_label == "Right":
            return tip.x < pip.x - 0.05
        else:
            return tip.x > pip.x + 0.05
    # demais dedos: eixo Y (origem no topo) - mais rigoroso
    return tip.y < pip.y - 0.05

def count_extended(lm, handed_label):
    cnt = 0
    for name in ["thumb","index","middle","ring","pinky"]:
        if finger_extended(lm, TIP[name], PIP[name], handed_label):
            cnt += 1
    return cnt

# ===== Hist√≥rico de Gestos =====
gesture_history = []

def add_gesture_to_history(gesture):
    """Adiciona gesto ao hist√≥rico e mant√©m tamanho da janela"""
    gesture_history.append(gesture)
    if len(gesture_history) > GESTURE_WINDOW_SIZE:
        gesture_history.pop(0)

def get_stable_gesture():
    """Retorna gesto est√°vel baseado no hist√≥rico ou 'neutral' se inconsistente"""
    if len(gesture_history) < GESTURE_WINDOW_SIZE:
        return "neutral"  # aguarda janela completa
    
    # Conta ocorr√™ncias de cada gesto
    gesture_counts = {}
    for gesture in gesture_history:
        gesture_counts[gesture] = gesture_counts.get(gesture, 0) + 1
    
    # Encontra o gesto mais frequente
    most_common_gesture = max(gesture_counts, key=gesture_counts.get)
    most_common_count = gesture_counts[most_common_gesture]
    
    # Verifica se atende o threshold de consist√™ncia
    consistency_ratio = most_common_count / len(gesture_history)
    
    if consistency_ratio >= CONSISTENCY_THRESHOLD and most_common_gesture != "neutral":
        return most_common_gesture
    
    return "neutral"

# ===== Gesto -> A√ß√£o =====
# 1 dedo: pr√≥ximo; 2 dedos: anterior; 3 dedos: in√≠cio; 4 dedos: fim; sen√£o: neutro
def classify_gesture(lm, handed_label):
    n = count_extended(lm, handed_label)
    if n == 1: return "next"      # um dedo levantado
    if n == 2: return "prev"      # dois dedos levantados
    if n == 3: return "home"      # tr√™s dedos levantados
    if n == 4: return "end"       # quatro dedos levantados
    return "neutral"

def press_next():
    kb.emit_click(uinput.KEY_RIGHT)

def press_prev():
    kb.emit_click(uinput.KEY_LEFT)

def press_home():
    kb.emit_click(uinput.KEY_HOME)

def press_end():
    kb.emit_click(uinput.KEY_END)

# ===== Controle de Estado =====
class WaveControlCLI:
    def __init__(self):
        self.is_running = False
        self.cap = None
        self.start_ts = None
        self.last_action = "neutral"
        self.action_executed = False
        
    def find_camera(self):
        """Tenta encontrar uma c√¢mera dispon√≠vel testando v√°rios √≠ndices"""
        print("üîç Procurando c√¢meras dispon√≠veis...")
        
        for i in range(10):  # Testa √≠ndices 0-9
            cap = cv2.VideoCapture(i)
            if cap.isOpened():
                # Testa se consegue ler um frame
                ret, _ = cap.read()
                if ret:
                    print(f"‚úÖ C√¢mera encontrada no √≠ndice {i}")
                    return cap, i
                cap.release()
                
        return None, -1
    
    def start_detection(self):
        global gesture_history, hands
        gesture_history.clear()
        
        print("üéØ WaveControl CLI - Iniciando detec√ß√£o de gestos...")
        
        self.cap, cam_index = self.find_camera()
        if self.cap is None:
            print("‚ùå Erro: Nenhuma c√¢mera dispon√≠vel encontrada!")
            print("   Poss√≠veis solu√ß√µes:")
            print("   ‚Ä¢ Conecte uma webcam USB")
            print("   ‚Ä¢ Verifique se a c√¢mera n√£o est√° sendo usada por outro app")
            print("   ‚Ä¢ Reinicie o sistema se necess√°rio")
            return False
        
        # Inicializa MediaPipe ap√≥s abrir a c√¢mera
        print("ü§ñ Inicializando MediaPipe...")
        hands = mp_hands.Hands(
            max_num_hands=1,
            model_complexity=0,
            min_detection_confidence=MIN_DET,
            min_tracking_confidence=MIN_TRK,
        )
            
        self.is_running = True
        self.start_ts = time.time()
        
        print("‚úÖ C√¢mera iniciada com sucesso!")
        print("‚è±Ô∏è  Calibrando por 2 segundos...")
        print("\nüìã Gestos dispon√≠veis:")
        print("   üëÜ 1 dedo ‚Üí Pr√≥ximo slide")
        print("   ‚úåÔ∏è  2 dedos ‚Üí Slide anterior")
        print("   ü§ü 3 dedos ‚Üí In√≠cio da apresenta√ß√£o")
        print("   üñêÔ∏è  4 dedos ‚Üí Fim da apresenta√ß√£o")
        print("   ‚úä M√£o fechada ‚Üí Neutro")
        print("\nüí° Mantenha a m√£o vis√≠vel na c√¢mera!")
        print("üõë Pressione Ctrl+C para parar\n")
        
        return True
        
    def process_video(self):
        frame_count = 0
        
        while self.is_running and self.cap and self.cap.isOpened():
            try:
                ok, frame = self.cap.read()
                if not ok:
                    break
                    
                frame = cv2.flip(frame, 1)
                rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                res = hands.process(rgb)
                
                raw_action = "neutral"
                handed = "Right"
                
                if res.multi_hand_landmarks:
                    lm = res.multi_hand_landmarks[0]
                    if res.multi_handedness and len(res.multi_handedness) > 0:
                        handed = res.multi_handedness[0].classification[0].label
                    raw_action = classify_gesture(lm.landmark, handed)
                
                # Adiciona gesto ao hist√≥rico e obt√©m gesto est√°vel
                add_gesture_to_history(raw_action)
                action = get_stable_gesture()
                
                now = time.time()
                
                # Calibra√ß√£o inicial
                if now - self.start_ts < CALIBRATION_S:
                    if frame_count % 30 == 0:  # Mostra a cada segundo
                        remaining = int(CALIBRATION_S - (now - self.start_ts))
                        print(f"‚è±Ô∏è  Calibrando... {remaining}s restantes")
                else:
                    # L√≥gica de execu√ß√£o de a√ß√µes
                    if action == "neutral":
                        if self.action_executed:
                            self.action_executed = False
                            print("‚úÖ Sistema pronto para nova a√ß√£o")
                    elif action != "neutral" and not self.action_executed:
                        if action == "next":
                            press_next()
                            print("‚û°Ô∏è  PR√ìXIMO slide executado")
                        elif action == "prev":
                            press_prev()
                            print("‚¨ÖÔ∏è  ANTERIOR slide executado")
                        elif action == "home":
                            press_home()
                            print("üè† IN√çCIO da apresenta√ß√£o")
                        elif action == "end":
                            press_end()
                            print("üîö FIM da apresenta√ß√£o")
                        self.action_executed = True
                        self.last_action = action
                    elif action != "neutral" and self.action_executed:
                        # N√£o mostra mensagem repetitiva, apenas aguarda
                        pass
                
                frame_count += 1
                time.sleep(0.03)  # ~30 FPS
                
            except KeyboardInterrupt:
                print("\nüõë Interrompido pelo usu√°rio")
                break
                
    def stop_detection(self):
        self.is_running = False
        if self.cap:
            self.cap.release()
        print("üì∑ C√¢mera desconectada")
        print("üëã WaveControl CLI finalizado")

def list_cameras():
    """Lista todas as c√¢meras dispon√≠veis"""
    print("üîç Listando c√¢meras dispon√≠veis:")
    found = False
    
    for i in range(10):
        cap = cv2.VideoCapture(i)
        if cap.isOpened():
            ret, _ = cap.read()
            if ret:
                print(f"   üì∑ C√¢mera {i}: Dispon√≠vel")
                found = True
            cap.release()
    
    if not found:
        print("   ‚ùå Nenhuma c√¢mera encontrada")
    print()

def main():
    import sys
    
    print("üåä WaveControl CLI")
    print("================")
    
    # Verifica argumentos da linha de comando
    if len(sys.argv) > 1:
        if sys.argv[1] in ["-l", "--list", "list"]:
            list_cameras()
            return
        elif sys.argv[1] in ["-h", "--help", "help"]:
            print("Uso:")
            print("  python3 main_cli.py          # Executar detec√ß√£o de gestos")
            print("  python3 main_cli.py -l       # Listar c√¢meras dispon√≠veis")
            print("  python3 main_cli.py -h       # Mostrar esta ajuda")
            print()
            print("Gestos:")
            print("  üëÜ 1 dedo ‚Üí Pr√≥ximo slide")
            print("  ‚úåÔ∏è  2 dedos ‚Üí Slide anterior")
            print("  ü§ü 3 dedos ‚Üí In√≠cio da apresenta√ß√£o")
            print("  üñêÔ∏è  4 dedos ‚Üí Fim da apresenta√ß√£o")
            print("  ‚úä M√£o fechada ‚Üí Neutro")
            return
    
    try:
        cli = WaveControlCLI()
        if cli.start_detection():
            cli.process_video()
        cli.stop_detection()
        
    except Exception as e:
        print(f"‚ùå Erro inesperado: {e}")
    
    finally:
        if hands:
            hands.close()

if __name__ == "__main__":
    main()
